{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cf01df-787c-49ef-83f2-e08bce88506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6b4896-2494-4d85-ae7b-96ab875f251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c2921e-45c2-4080-8c90-089daeeceba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lcdb\n",
    "import json\n",
    "import lcpfn \n",
    "import torch as th\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eac6fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"C:\\\\Users\\\\mjaic\\\\OneDrive\\\\Desktop\\\\Delft\\\\Year 1\\\\Q3\\\\Deep Learning\\\\deep-learning-project\\\\notebooks\\data.json\"\n",
    "\n",
    "def readDatasetJson(path):\n",
    "    f = open(path)\n",
    "\n",
    "    dataset = json.load(f)\n",
    "    # print(len(dataset))\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for v in dataset.values():\n",
    "        x.append(v[0])\n",
    "        y.append(v[1])\n",
    "        \n",
    "    x_true = th.Tensor(x)\n",
    "    y_true = th.Tensor(y)\n",
    "    \n",
    "    return x_true, y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def find_file(root_dir, target_filename):\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        if target_filename in files:\n",
    "            return os.path.join(root, target_filename)\n",
    "    \n",
    "    # If the loop completes without returning, the file was not found\n",
    "    return None\n",
    "\n",
    "def find_data():\n",
    "    return find_file(os.getcwd(), 'data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return readDatasetJson(find_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f53cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function producing batches for PFN training\n",
    "def get_batch(\n",
    "    batch_size,\n",
    "    seq_len,\n",
    "    num_features,\n",
    "    device=\"cpu\",\n",
    "    noisy_target=True,\n",
    "    **_,\n",
    "):\n",
    "    assert num_features == 1\n",
    "\n",
    "    x_data, y_data = get_data()\n",
    "    x_data = x_data[:batch_size, :]\n",
    "    y_data = y_data[:batch_size, :]\n",
    "\n",
    "    y_data_noisy = y_data.clone()\n",
    "\n",
    "    # print(x_data.shape)\n",
    "    # print(y_data.shape)\n",
    "\n",
    "    x_data = x_data.view((num_features, batch_size, seq_len)).transpose(2, 0).to(device)\n",
    "    y_data = y_data.transpose(1, 0).to(device)\n",
    "    y_data_noisy = y_data.clone()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # x = np.arange(1, seq_len + 1)\n",
    "    # y_target = np.empty((batch_size, seq_len), dtype=float)\n",
    "    # y_noisy = np.empty((batch_size, seq_len), dtype=float)\n",
    "    # x_data, y_data = get_data() # uses numpy rng\n",
    "    \n",
    "    # for i in range(batch_size):    \n",
    "    #     if noisy_target:\n",
    "    #         y_noisy[i] = y_data[i]\n",
    "    #         y_target[i] = y_data[i]\n",
    "    #     else:\n",
    "    #         y_target[i], y_noisy[i] = y_data[i]\n",
    "    # # turn numpy arrays into correctly shaped torch tensors & move them to device\n",
    "    # x = (\n",
    "    #     th.Tensor(x_data[0])\n",
    "    #     .repeat((num_features, batch_size, 1))\n",
    "    #     .transpose(2, 0)\n",
    "    #     .to(device)\n",
    "    # )\n",
    "    # y_target = th.from_numpy(y_target).transpose(1, 0).to(device)\n",
    "    # y_noisy = th.from_numpy(y_noisy).transpose(1, 0).to(device)\n",
    "\n",
    "    # # changes\n",
    "    # x = x.float()\n",
    "    # y_target = y_target.float()\n",
    "    # y_noisy = y_noisy.float()\n",
    "    \n",
    "    # return x, y_noisy, y_target\n",
    "\n",
    "    return x_data, y_data, y_data_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa7ce7fb-9c9f-4858-ab2e-b86bd48d15c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu:0 device\n",
      "init dist\n",
      "Not using distributed\n",
      "DataLoader.__dict__ {'num_steps': 100, 'get_batch_kwargs': {'batch_size': 100, 'eval_pos_seq_len_sampler': <function train.<locals>.eval_pos_seq_len_sampler at 0x7160d5283280>, 'seq_len_maximum': 26, 'device': 'cpu:0', 'num_features': 1, 'hyperparameters': {}}, 'num_features': 1}\n",
      "Style definition: None\n",
      "Using a Transformer with 6.46 M parameters\n"
     ]
    }
   ],
   "source": [
    "result = lcpfn.train_lcpfn(get_batch_func=get_batch, \n",
    "                         seq_len=26,\n",
    "                         emsize=256,\n",
    "                         nlayers=12,\n",
    "                         lr=0.001,\n",
    "                         batch_size=100,\n",
    "                         epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
